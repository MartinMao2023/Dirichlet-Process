\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{alphaGo,alphaStar}
\citation{openAI5}
\citation{MBRL,black_box_search,policy_search}
\citation{curse_of_dim}
\citation{QD}
\citation{EvoRBC}
\citation{RTE}
\citation{GP}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}\protected@file@percent }
\citation{knn}
\citation{k-means}
\citation{QD,Map-Elites}
\citation{Q-Dax}
\citation{evorbc_conf}
\citation{Q-Dax}
\@writefile{toc}{\contentsline {section}{\numberline {II}Background}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Quality-Diversity Optimization}{2}{subsection.2.1}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces MAP-Elites}}{2}{algorithm.1}\protected@file@percent }
\newlabel{MAP-Elites}{{1}{2}{Quality-Diversity Optimization}{ALC@unique.18}{}}
\citation{GP,GP_posterior}
\citation{GP,Matern}
\citation{DP}
\citation{Gibbs_sampling,Gibbs}
\citation{variational_method}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}Gaussian Process}{3}{subsection.2.2}\protected@file@percent }
\newlabel{multi_normal}{{1}{3}{Gaussian Process}{equation.2.1}{}}
\newlabel{covariance_matrix}{{2}{3}{Gaussian Process}{equation.2.2}{}}
\newlabel{GP_posterior}{{3}{3}{Gaussian Process}{equation.2.3}{}}
\newlabel{RBF_kernel}{{4}{3}{Gaussian Process}{equation.2.4}{}}
\newlabel{Matern}{{5}{3}{Gaussian Process}{equation.2.5}{}}
\newlabel{distance_metric}{{6}{3}{Gaussian Process}{equation.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-C}}Dirichlet Process Mixture Model}{3}{subsection.2.3}\protected@file@percent }
\newlabel{finite_mixture_model}{{7}{3}{Dirichlet Process Mixture Model}{equation.2.7}{}}
\newlabel{Dirichlet_distribution}{{8}{3}{Dirichlet Process Mixture Model}{equation.2.8}{}}
\newlabel{indicator_posterior}{{9}{3}{Dirichlet Process Mixture Model}{equation.2.9}{}}
\citation{MCMC}
\citation{Bayesian_mixture}
\citation{EM}
\citation{infinite_GMM}
\citation{RTE}
\citation{MCTS}
\newlabel{configuration_probability}{{10}{4}{Dirichlet Process Mixture Model}{equation.2.10}{}}
\newlabel{indicator_prior}{{11}{4}{Dirichlet Process Mixture Model}{equation.2.11}{}}
\newlabel{indicator_posterior_2}{{12}{4}{Dirichlet Process Mixture Model}{equation.2.12}{}}
\newlabel{indicator_posterior_3}{{13}{4}{Dirichlet Process Mixture Model}{equation.2.13}{}}
\newlabel{integral_1}{{14}{4}{Dirichlet Process Mixture Model}{equation.2.14}{}}
\newlabel{integral_2}{{15}{4}{Dirichlet Process Mixture Model}{equation.2.15}{}}
\newlabel{posterior_likelihood}{{16}{4}{Dirichlet Process Mixture Model}{equation.2.16}{}}
\@writefile{toc}{\contentsline {section}{\numberline {III}Related Works}{4}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Reset-free Trial-and-Error Learning}{4}{subsection.3.1}\protected@file@percent }
\citation{RTE}
\citation{APROL}
\citation{CF_recom}
\citation{GPCF}
\citation{DKT}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}Adaptive Prior selection for Repertoire-based Online Learning}{5}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}Gaussian Process with Collaborative filtering}{5}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {IV}Methodology}{5}{section.4}\protected@file@percent }
\citation{infinite_MGP,variational_MGP}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-A}}Linear Prior Mean Function}{6}{subsection.4.1}\protected@file@percent }
\newlabel{dynamics_assumption}{{17}{6}{Linear Prior Mean Function}{equation.4.17}{}}
\newlabel{Taylor_expansion}{{18}{6}{Linear Prior Mean Function}{equation.4.18}{}}
\newlabel{approximation}{{19}{6}{Linear Prior Mean Function}{equation.4.19}{}}
\newlabel{dynamics_diff}{{20}{6}{Linear Prior Mean Function}{equation.4.20}{}}
\newlabel{linear_form}{{21}{6}{Linear Prior Mean Function}{equation.4.21}{}}
\citation{PCA}
\newlabel{linear_combination}{{22}{7}{Linear Prior Mean Function}{equation.4.22}{}}
\newlabel{SVD}{{23}{7}{Linear Prior Mean Function}{equation.4.23}{}}
\newlabel{ATA}{{24}{7}{Linear Prior Mean Function}{equation.4.24}{}}
\newlabel{basis}{{25}{7}{Linear Prior Mean Function}{equation.4.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-B}}Determine the Input Space}{7}{subsection.4.2}\protected@file@percent }
\newlabel{linear_form_for_beta}{{26}{7}{Determine the Input Space}{equation.4.26}{}}
\newlabel{beta}{{27}{7}{Determine the Input Space}{equation.4.27}{}}
\citation{Kasa_method}
\citation{circle_fitting}
\citation{L-BFGS-B}
\newlabel{cov}{{28}{8}{Determine the Input Space}{equation.4.28}{}}
\newlabel{PCA}{{29}{8}{Determine the Input Space}{equation.4.29}{}}
\newlabel{input_space}{{30}{8}{Determine the Input Space}{equation.4.30}{}}
\newlabel{prior_mean_function}{{31}{8}{Determine the Input Space}{equation.4.31}{}}
\newlabel{fig_first_case}{{1a}{8}{Subfigure 1a}{subfigure.1.1}{}}
\newlabel{sub@fig_first_case}{{(a)}{a}{Subfigure 1a\relax }{subfigure.1.1}{}}
\newlabel{fig_second_case}{{1b}{8}{Subfigure 1b}{subfigure.1.2}{}}
\newlabel{sub@fig_second_case}{{(b)}{b}{Subfigure 1b\relax }{subfigure.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example of PCA transform. Original data distribution is given by (a), where the two axes are highly correlated. (b) is the resultant distribution after applying Eq. (\ref  {input_space}), where the correlation is removed.}}{8}{figure.1}\protected@file@percent }
\newlabel{PCA_outcome}{{1}{8}{Example of PCA transform. Original data distribution is given by (a), where the two axes are highly correlated. (b) is the resultant distribution after applying Eq. (\ref {input_space}), where the correlation is removed}{figure.1}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{8}{subfigure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{8}{subfigure.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-C}}Choosing the Dynamics Representation}{8}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Arc trajectories with different $v$, $\omega $ and $\varphi $. Curve 1 has $v=0.5$, $\omega = 30^\circ /s$ and $\varphi = 90^\circ $. Curve 2 has $v=0.25$, $\omega = 0$ and $\varphi = 90^\circ $. Curve 3 shares the same $v$ and $\omega $ with curve 1 but having $\varphi = 0$. All the curves are generated after 4 seconds of movement. }}{8}{figure.2}\protected@file@percent }
\newlabel{arcs}{{2}{8}{Arc trajectories with different $v$, $\omega $ and $\varphi $. Curve 1 has $v=0.5$, $\omega = 30^\circ /s$ and $\varphi = 90^\circ $. Curve 2 has $v=0.25$, $\omega = 0$ and $\varphi = 90^\circ $. Curve 3 shares the same $v$ and $\omega $ with curve 1 but having $\varphi = 0$. All the curves are generated after 4 seconds of movement}{figure.2}{}}
\newlabel{circle_equation}{{32}{8}{Choosing the Dynamics Representation}{equation.4.32}{}}
\newlabel{circle_error}{{33}{8}{Choosing the Dynamics Representation}{equation.4.33}{}}
\citation{error_analysis}
\newlabel{delta_theta}{{34}{9}{Choosing the Dynamics Representation}{equation.4.34}{}}
\newlabel{all_three_parameters}{{35}{9}{Choosing the Dynamics Representation}{equation.4.35}{}}
\newlabel{summed_variance}{{36}{9}{Choosing the Dynamics Representation}{equation.4.36}{}}
\newlabel{position_from_arc}{{37}{9}{Choosing the Dynamics Representation}{equation.4.37}{}}
\newlabel{error_prapagation}{{38}{9}{Choosing the Dynamics Representation}{equation.4.38}{}}
\newlabel{combined_error_relation}{{39}{9}{Choosing the Dynamics Representation}{equation.4.39}{}}
\newlabel{noises_for_v_w_phi}{{40}{9}{Choosing the Dynamics Representation}{equation.4.40}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-D}}Clustering the Dynamics with Dirichlet Processes}{9}{subsection.4.4}\protected@file@percent }
\newlabel{MLE}{{41}{10}{Clustering the Dynamics with Dirichlet Processes}{equation.4.41}{}}
\newlabel{nll}{{42}{10}{Clustering the Dynamics with Dirichlet Processes}{equation.4.42}{}}
\newlabel{modified_covariance_matrix}{{43}{10}{Clustering the Dynamics with Dirichlet Processes}{equation.4.43}{}}
\newlabel{MC_prior_integral}{{44}{10}{Clustering the Dynamics with Dirichlet Processes}{equation.4.44}{}}
\newlabel{MC_posterior}{{45}{10}{Clustering the Dynamics with Dirichlet Processes}{equation.4.45}{}}
\newlabel{posterior_convergence_estimate}{{46}{10}{Clustering the Dynamics with Dirichlet Processes}{equation.4.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Example of the convergence of parameter posterior in DPMM. Data are sampled from a infinite mixture of Gaussians, where the variance is fixed at 4, and the mean is given by a Gaussian mixture as the prior. As the cluster grows larger, the posterior of the mean becomes more narrowed and centred at the ground truth (5.5). }}{10}{figure.3}\protected@file@percent }
\newlabel{posterior_convergence}{{3}{10}{Example of the convergence of parameter posterior in DPMM. Data are sampled from a infinite mixture of Gaussians, where the variance is fixed at 4, and the mean is given by a Gaussian mixture as the prior. As the cluster grows larger, the posterior of the mean becomes more narrowed and centred at the ground truth (5.5)}{figure.3}{}}
\newlabel{refitted_weights}{{47}{11}{Clustering the Dynamics with Dirichlet Processes}{equation.4.47}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-E}}Learning the Dynamics Online}{11}{subsection.4.5}\protected@file@percent }
\newlabel{trained_mixture_model}{{48}{11}{Learning the Dynamics Online}{equation.4.48}{}}
\newlabel{MGP_posterior}{{49}{11}{Learning the Dynamics Online}{equation.4.49}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces DP Clustering}}{11}{algorithm.2}\protected@file@percent }
\newlabel{DP_clustering}{{2}{11}{Clustering the Dynamics with Dirichlet Processes}{ALC@unique.51}{}}
\newlabel{MGP_indicator}{{50}{11}{Learning the Dynamics Online}{equation.4.50}{}}
\newlabel{posterior_convergence_simplification}{{51}{11}{Learning the Dynamics Online}{equation.4.51}{}}
\citation{PyBullet}
\citation{cully2015robots}
\newlabel{simplified_distortion}{{52}{12}{Learning the Dynamics Online}{equation.4.52}{}}
\newlabel{simplified_indicator}{{53}{12}{Learning the Dynamics Online}{equation.4.53}{}}
\@writefile{toc}{\contentsline {section}{\numberline {V}Experiment Design}{12}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-A}}Robot Setup}{12}{subsection.5.1}\protected@file@percent }
\newlabel{PID}{{54}{12}{Robot Setup}{equation.5.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The Ant robot in PyBullet simulation. The four motors mounted on the body can rotate from $-40^{\circ }$ to $40^{\circ }$. The knee flexion angle for each leg ranges from $30^{\circ }$ to $100^{\circ }$. }}{12}{figure.4}\protected@file@percent }
\newlabel{Ant_robot}{{4}{12}{The Ant robot in PyBullet simulation. The four motors mounted on the body can rotate from $-40^{\circ }$ to $40^{\circ }$. The knee flexion angle for each leg ranges from $30^{\circ }$ to $100^{\circ }$}{figure.4}{}}
\citation{QDgym}
\citation{cully2015robots}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The periodic motor targets corresponding to $\alpha = 0.8$, $\phi =100$ ms and $\tau =0.6$. The squared wave is smoothed by a Gaussian kernel with $\sigma = 100$ ms. }}{13}{figure.5}\protected@file@percent }
\newlabel{targets}{{5}{13}{The periodic motor targets corresponding to $\alpha = 0.8$, $\phi =100$ ms and $\tau =0.6$. The squared wave is smoothed by a Gaussian kernel with $\sigma = 100$ ms}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The robot walking with one leg (left blue-yellow leg) damaged. The knee flexion angle of this leg is fixed at $30^{\circ }$ to reduce contact with the ground. }}{13}{figure.6}\protected@file@percent }
\newlabel{damaged_robot}{{6}{13}{The robot walking with one leg (left blue-yellow leg) damaged. The knee flexion angle of this leg is fixed at $30^{\circ }$ to reduce contact with the ground}{figure.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-B}}Generating the Repertoire with MAP-Elites}{13}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-C}}Determine the Coordinates of Policies}{13}{subsection.5.3}\protected@file@percent }
\citation{elbow}
\@writefile{loa}{\contentsline {algorithm}{\numberline {3}{\ignorespaces Crossover}}{14}{algorithm.3}\protected@file@percent }
\newlabel{Crossover}{{3}{14}{Generating the Repertoire with MAP-Elites}{ALC@unique.74}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The resultant repertoire after 4000 MAP-Elites iterations. The coordinates correspond to the 2D displacement brought by each policy, and the color indicates the fitness score. Policies leading to smaller displacements have bigger fitnesses as they require lesser electric cost. }}{14}{figure.7}\protected@file@percent }
\newlabel{original_repertoire}{{7}{14}{The resultant repertoire after 4000 MAP-Elites iterations. The coordinates correspond to the 2D displacement brought by each policy, and the color indicates the fitness score. Policies leading to smaller displacements have bigger fitnesses as they require lesser electric cost}{figure.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The trajectories of 6 elementary policies in default simulation settings. The dashed lines denote the predicted trajectories in arc-based representation with the parameters calculated using Eq. (\ref  {all_three_parameters}). The fact that the predicted curves stick closely to the actual trajectories indicates such representation being successful. }}{14}{figure.8}\protected@file@percent }
\newlabel{baseline_trajectories}{{8}{14}{The trajectories of 6 elementary policies in default simulation settings. The dashed lines denote the predicted trajectories in arc-based representation with the parameters calculated using Eq. (\ref {all_three_parameters}). The fact that the predicted curves stick closely to the actual trajectories indicates such representation being successful}{figure.8}{}}
\newlabel{SVD_for_arc}{{55}{14}{Determine the Coordinates of Policies}{equation.5.55}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces The mean squared distance error against the number of basis. The elbows for the two curves are both at 5. }}{15}{figure.9}\protected@file@percent }
\newlabel{original_elbow}{{9}{15}{The mean squared distance error against the number of basis. The elbows for the two curves are both at 5}{figure.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces The mean squared distance error against the number of basis after filtering out the policies with large errors. }}{15}{figure.10}\protected@file@percent }
\newlabel{filtered_elbow}{{10}{15}{The mean squared distance error against the number of basis after filtering out the policies with large errors}{figure.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The remaining repertoire after filtering. }}{15}{figure.11}\protected@file@percent }
\newlabel{filtered_repertoire}{{11}{15}{The remaining repertoire after filtering}{figure.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-D}}Clustering the Collaboratively Collected Data}{15}{subsection.5.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-E}}Model-Based Adaptation in a Maze}{15}{subsection.5.5}\protected@file@percent }
\citation{DWA}
\citation{RTE}
\@writefile{lot}{\contentsline {table}{\numberline {I}{\ignorespaces Collaboratively Collected Data}}{16}{table.1}\protected@file@percent }
\newlabel{data}{{I}{16}{Collaboratively Collected Data}{table.1}{}}
\newlabel{objective_function}{{56}{16}{Model-Based Adaptation in a Maze}{equation.5.56}{}}
\newlabel{predicted_subsequent_state}{{57}{16}{Model-Based Adaptation in a Maze}{equation.5.57}{}}
\newlabel{predicted_mean}{{58}{16}{Model-Based Adaptation in a Maze}{equation.5.58}{}}
\newlabel{penalty}{{59}{16}{Model-Based Adaptation in a Maze}{equation.5.59}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces The floor-plan of the maze. The starting area is a rectangle with width equals to 1 and height equals to 2. To allow some exploration at start, the width of the tunnel is 5 before the first turning and then reduces to 2.5 for the rest of the sections. }}{16}{figure.12}\protected@file@percent }
\newlabel{maze}{{12}{16}{The floor-plan of the maze. The starting area is a rectangle with width equals to 1 and height equals to 2. To allow some exploration at start, the width of the tunnel is 5 before the first turning and then reduces to 2.5 for the rest of the sections}{figure.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {VI}Results and Analysis}{16}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VI-A}}Dirichlet Process Clustering}{16}{subsection.6.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Cluster assignment of the data in Table \ref  {data} after applying our DP clustering method. (a) is the result using displacement-based representation, and (b) is the one for arc-based representation.}}{17}{figure.13}\protected@file@percent }
\newlabel{clustering_results}{{13}{17}{Cluster assignment of the data in Table \ref {data} after applying our DP clustering method. (a) is the result using displacement-based representation, and (b) is the one for arc-based representation}{figure.13}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{17}{subfigure.13.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{17}{subfigure.13.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VI-B}}Dynamics Learning}{17}{subsection.6.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {VI-C}}Maze Adaptation}{17}{subsection.6.3}\protected@file@percent }
\newlabel{case_0}{{14a}{18}{Subfigure 14a}{subfigure.14.1}{}}
\newlabel{sub@case_0}{{(a)}{a}{Subfigure 14a\relax }{subfigure.14.1}{}}
\newlabel{case_1}{{14b}{18}{Subfigure 14b}{subfigure.14.2}{}}
\newlabel{sub@case_1}{{(b)}{b}{Subfigure 14b\relax }{subfigure.14.2}{}}
\newlabel{case_2}{{14c}{18}{Subfigure 14c}{subfigure.14.3}{}}
\newlabel{sub@case_2}{{(c)}{c}{Subfigure 14c\relax }{subfigure.14.3}{}}
\newlabel{case_3}{{14d}{18}{Subfigure 14d}{subfigure.14.4}{}}
\newlabel{sub@case_3}{{(d)}{d}{Subfigure 14d\relax }{subfigure.14.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces The prediction error versus the step taken in each environment. The error is defined to be the mean-squared distance between the predicted final position and the actual final position. }}{18}{figure.14}\protected@file@percent }
\newlabel{dynamics_learning}{{14}{18}{The prediction error versus the step taken in each environment. The error is defined to be the mean-squared distance between the predicted final position and the actual final position}{figure.14}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{18}{subfigure.14.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{18}{subfigure.14.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{18}{subfigure.14.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{18}{subfigure.14.4}\protected@file@percent }
\newlabel{weight_2}{{15a}{18}{Subfigure 15a}{subfigure.15.1}{}}
\newlabel{sub@weight_2}{{(a)}{a}{Subfigure 15a\relax }{subfigure.15.1}{}}
\newlabel{weight_4}{{15b}{18}{Subfigure 15b}{subfigure.15.2}{}}
\newlabel{sub@weight_4}{{(b)}{b}{Subfigure 15b\relax }{subfigure.15.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces The change of the posterior weight of each cluster versus the number of steps taken. These data correspond to the model using displacement-based dynamics representation. }}{18}{figure.15}\protected@file@percent }
\newlabel{weights}{{15}{18}{The change of the posterior weight of each cluster versus the number of steps taken. These data correspond to the model using displacement-based dynamics representation}{figure.15}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{18}{subfigure.15.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{18}{subfigure.15.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {II}{\ignorespaces Maze Adaptation Details}}{19}{table.2}\protected@file@percent }
\newlabel{detailed_data}{{II}{19}{Maze Adaptation Details}{table.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Dynamics learning in an unseen environment. For this environment, the robot damage is in the leg 4, the friction coefficient is 0.77 and the torque scale is 0.82}}{19}{figure.16}\protected@file@percent }
\newlabel{new_env}{{16}{19}{Dynamics learning in an unseen environment. For this environment, the robot damage is in the leg 4, the friction coefficient is 0.77 and the torque scale is 0.82}{figure.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Dynamics learning performance after having collected an episode of interactions from this environment. With dataset updated, 20 extra Gibbs sampling sweeps were conducted to identify the best indicator configuration.}}{19}{figure.17}\protected@file@percent }
\newlabel{new_adapt}{{17}{19}{Dynamics learning performance after having collected an episode of interactions from this environment. With dataset updated, 20 extra Gibbs sampling sweeps were conducted to identify the best indicator configuration}{figure.17}{}}
\bibstyle{unsrt}
\bibdata{reference}
\bibcite{alphaGo}{1}
\bibcite{alphaStar}{2}
\bibcite{openAI5}{3}
\bibcite{MBRL}{4}
\bibcite{black_box_search}{5}
\bibcite{policy_search}{6}
\bibcite{curse_of_dim}{7}
\bibcite{QD}{8}
\bibcite{EvoRBC}{9}
\newlabel{maze_0}{{18a}{20}{Subfigure 18a}{subfigure.18.1}{}}
\newlabel{sub@maze_0}{{(a)}{a}{Subfigure 18a\relax }{subfigure.18.1}{}}
\newlabel{maze_1}{{18b}{20}{Subfigure 18b}{subfigure.18.2}{}}
\newlabel{sub@maze_1}{{(b)}{b}{Subfigure 18b\relax }{subfigure.18.2}{}}
\newlabel{maze_2}{{18c}{20}{Subfigure 18c}{subfigure.18.3}{}}
\newlabel{sub@maze_2}{{(c)}{c}{Subfigure 18c\relax }{subfigure.18.3}{}}
\newlabel{maze_3}{{18d}{20}{Subfigure 18d}{subfigure.18.4}{}}
\newlabel{sub@maze_3}{{(d)}{d}{Subfigure 18d\relax }{subfigure.18.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces The maze adaptation performance of the robots using different models. To avoid getting any unrepresentative results due to initial state, we randomly initialize the robot 100 times. Each time the robot is randomly placed in the starting area with orientation $\theta \sim \mathcal  {N}(0, 30^{\circ })$. Since the maze is U-shaped, we use effective distance instead of the distance to the goal to track the progress of the robot. The effective distance is defined to be the projection on the suggested path, which is the distance on the path that is closet to the robot's current position. The effective distance at the exit is 55.386. }}{20}{figure.18}\protected@file@percent }
\newlabel{navigation_results}{{18}{20}{The maze adaptation performance of the robots using different models. To avoid getting any unrepresentative results due to initial state, we randomly initialize the robot 100 times. Each time the robot is randomly placed in the starting area with orientation $\theta \sim \mathcal {N}(0, 30^{\circ })$. Since the maze is U-shaped, we use effective distance instead of the distance to the goal to track the progress of the robot. The effective distance is defined to be the projection on the suggested path, which is the distance on the path that is closet to the robot's current position. The effective distance at the exit is 55.386}{figure.18}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{20}{subfigure.18.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{20}{subfigure.18.2}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {}}}{20}{subfigure.18.3}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(d)}{\ignorespaces {}}}{20}{subfigure.18.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VII}Conclusion}{20}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{20}{section*.1}\protected@file@percent }
\bibcite{RTE}{10}
\bibcite{GP}{11}
\bibcite{knn}{12}
\bibcite{k-means}{13}
\bibcite{Map-Elites}{14}
\bibcite{Q-Dax}{15}
\bibcite{evorbc_conf}{16}
\bibcite{GP_posterior}{17}
\bibcite{Matern}{18}
\bibcite{DP}{19}
\bibcite{Gibbs_sampling}{20}
\bibcite{Gibbs}{21}
\bibcite{variational_method}{22}
\bibcite{MCMC}{23}
\bibcite{Bayesian_mixture}{24}
\bibcite{EM}{25}
\bibcite{infinite_GMM}{26}
\bibcite{MCTS}{27}
\bibcite{APROL}{28}
\bibcite{CF_recom}{29}
\bibcite{GPCF}{30}
\bibcite{DKT}{31}
\bibcite{infinite_MGP}{32}
\bibcite{variational_MGP}{33}
\bibcite{PCA}{34}
\bibcite{Kasa_method}{35}
\bibcite{circle_fitting}{36}
\bibcite{L-BFGS-B}{37}
\bibcite{error_analysis}{38}
\bibcite{PyBullet}{39}
\bibcite{cully2015robots}{40}
\bibcite{QDgym}{41}
\bibcite{elbow}{42}
\bibcite{DWA}{43}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces The adaptation progress of the robots in the maze. The robots are initialized at the center of the starting area facing due right ($0^{\circ }$). The semitransparent notes connected by dash lines stands for executions that led to collisions. }}{21}{figure.19}\protected@file@percent }
\newlabel{navigation_process}{{19}{21}{The adaptation progress of the robots in the maze. The robots are initialized at the center of the starting area facing due right ($0^{\circ }$). The semitransparent notes connected by dash lines stands for executions that led to collisions}{figure.19}{}}
