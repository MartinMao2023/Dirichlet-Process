\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{alphaGo,alphaStar}
\citation{openAI5}
\citation{MBRL,black_box_search,policy_search}
\citation{curse_of_dim}
\citation{QD}
\citation{EvoRBC}
\citation{RTE}
\citation{GP}
\@writefile{toc}{\contentsline {section}{\numberline {I}Introduction}{1}{section.1}\protected@file@percent }
\citation{knn}
\citation{k-means}
\citation{QD,Map-Elites}
\citation{Q-Dax}
\citation{evorbc_conf}
\citation{Q-Dax}
\@writefile{toc}{\contentsline {section}{\numberline {II}Related Works}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-A}}Quality-Diversity Optimization}{2}{subsection.2.1}\protected@file@percent }
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces MAP-Elites}}{2}{algorithm.1}\protected@file@percent }
\newlabel{MAP-Elites}{{1}{2}{Quality-Diversity Optimization}{ALC@unique.16}{}}
\citation{GP,GP_posterior}
\citation{GP,Matern}
\citation{RTE}
\citation{MCTS}
\citation{RTE}
\citation{APROL}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-B}}Gaussian Process}{3}{subsection.2.2}\protected@file@percent }
\newlabel{multi_normal}{{1}{3}{Gaussian Process}{equation.2.1}{}}
\newlabel{covariance_matrix}{{2}{3}{Gaussian Process}{equation.2.2}{}}
\newlabel{GP_posterior}{{3}{3}{Gaussian Process}{equation.2.3}{}}
\newlabel{RBF_kernel}{{4}{3}{Gaussian Process}{equation.2.4}{}}
\newlabel{Matern}{{5}{3}{Gaussian Process}{equation.2.5}{}}
\newlabel{distance_metric}{{6}{3}{Gaussian Process}{equation.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-C}}Reset-free Trial-and-Error Learning}{3}{subsection.2.3}\protected@file@percent }
\citation{DP}
\citation{Gibbs_sampling,Gibbs}
\citation{variational_method}
\citation{MCMC}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {II-D}}Dirichlet Process Mixture Model}{4}{subsection.2.4}\protected@file@percent }
\newlabel{finite_mixture_model}{{7}{4}{Dirichlet Process Mixture Model}{equation.2.7}{}}
\newlabel{Dirichlet_distribution}{{8}{4}{Dirichlet Process Mixture Model}{equation.2.8}{}}
\newlabel{indicator_posterior}{{9}{4}{Dirichlet Process Mixture Model}{equation.2.9}{}}
\newlabel{configuration_probability}{{10}{4}{Dirichlet Process Mixture Model}{equation.2.10}{}}
\newlabel{indicator_prior}{{11}{4}{Dirichlet Process Mixture Model}{equation.2.11}{}}
\newlabel{indicator_posterior_2}{{12}{4}{Dirichlet Process Mixture Model}{equation.2.12}{}}
\newlabel{indicator_posterior_3}{{13}{4}{Dirichlet Process Mixture Model}{equation.2.13}{}}
\newlabel{integral_1}{{14}{4}{Dirichlet Process Mixture Model}{equation.2.14}{}}
\newlabel{integral_2}{{15}{4}{Dirichlet Process Mixture Model}{equation.2.15}{}}
\newlabel{posterior_likelihood}{{16}{4}{Dirichlet Process Mixture Model}{equation.2.16}{}}
\citation{Bayesian_mixture}
\citation{EM}
\citation{infinite_GMM}
\citation{infinite_MGP,variational_MGP}
\@writefile{toc}{\contentsline {section}{\numberline {III}Methodology}{5}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-A}}Linear Prior Mean Function}{5}{subsection.3.1}\protected@file@percent }
\newlabel{dynamics_assumption}{{17}{5}{Linear Prior Mean Function}{equation.3.17}{}}
\newlabel{Taylor_expansion}{{18}{5}{Linear Prior Mean Function}{equation.3.18}{}}
\newlabel{approximation}{{19}{6}{Linear Prior Mean Function}{equation.3.19}{}}
\newlabel{dynamics_diff}{{20}{6}{Linear Prior Mean Function}{equation.3.20}{}}
\newlabel{linear_form}{{21}{6}{Linear Prior Mean Function}{equation.3.21}{}}
\newlabel{linear_combination}{{22}{6}{Linear Prior Mean Function}{equation.3.22}{}}
\newlabel{SVD}{{23}{6}{Linear Prior Mean Function}{equation.3.23}{}}
\newlabel{ATA}{{24}{6}{Linear Prior Mean Function}{equation.3.24}{}}
\newlabel{basis}{{25}{6}{Linear Prior Mean Function}{equation.3.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-B}}Determine the Input Space}{6}{subsection.3.2}\protected@file@percent }
\citation{PCA}
\newlabel{linear_form_for_beta}{{26}{7}{Determine the Input Space}{equation.3.26}{}}
\newlabel{beta}{{27}{7}{Determine the Input Space}{equation.3.27}{}}
\newlabel{cov}{{28}{7}{Determine the Input Space}{equation.3.28}{}}
\newlabel{PCA}{{29}{7}{Determine the Input Space}{equation.3.29}{}}
\newlabel{input_space}{{30}{7}{Determine the Input Space}{equation.3.30}{}}
\newlabel{prior_mean_function}{{31}{7}{Determine the Input Space}{equation.3.31}{}}
\newlabel{fig_first_case}{{1a}{7}{Subfigure 1a}{subfigure.1.1}{}}
\newlabel{sub@fig_first_case}{{(a)}{a}{Subfigure 1a\relax }{subfigure.1.1}{}}
\newlabel{fig_second_case}{{1b}{7}{Subfigure 1b}{subfigure.1.2}{}}
\newlabel{sub@fig_second_case}{{(b)}{b}{Subfigure 1b\relax }{subfigure.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Example of PCA transform. Original data distribution is given by (a), where the two axes are highly correlated. (b) is the resultant distribution after applying Eq. (\ref  {input_space}), where the correlation is removed.}}{7}{figure.1}\protected@file@percent }
\newlabel{PCA_outcome}{{1}{7}{Example of PCA transform. Original data distribution is given by (a), where the two axes are highly correlated. (b) is the resultant distribution after applying Eq. (\ref {input_space}), where the correlation is removed}{figure.1}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {}}}{7}{subfigure.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {}}}{7}{subfigure.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-C}}Choosing the Dynamics Representation}{7}{subsection.3.3}\protected@file@percent }
\citation{Kasa_method}
\citation{circle_fitting}
\citation{L-BFGS-B}
\citation{error_analysis}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Arc trajectories with different $v$, $\omega $ and $\varphi $. Curve 1 has $v=0.5$, $\omega = 30^\circ /s$ and $\varphi = 90^\circ $. Curve 2 has $v=0.25$, $\omega = 0$ and $\varphi = 90^\circ $. Curve 3 shares the same $v$ and $\omega $ with curve 1 but having $\varphi = 0$. All the curves are generated after 4 seconds of movement. }}{8}{figure.2}\protected@file@percent }
\newlabel{arcs}{{2}{8}{Arc trajectories with different $v$, $\omega $ and $\varphi $. Curve 1 has $v=0.5$, $\omega = 30^\circ /s$ and $\varphi = 90^\circ $. Curve 2 has $v=0.25$, $\omega = 0$ and $\varphi = 90^\circ $. Curve 3 shares the same $v$ and $\omega $ with curve 1 but having $\varphi = 0$. All the curves are generated after 4 seconds of movement}{figure.2}{}}
\newlabel{circle_equation}{{32}{8}{Choosing the Dynamics Representation}{equation.3.32}{}}
\newlabel{circle_error}{{33}{8}{Choosing the Dynamics Representation}{equation.3.33}{}}
\newlabel{delta_theta}{{34}{8}{Choosing the Dynamics Representation}{equation.3.34}{}}
\newlabel{all_three_parameters}{{35}{8}{Choosing the Dynamics Representation}{equation.3.35}{}}
\newlabel{summed_variance}{{36}{8}{Choosing the Dynamics Representation}{equation.3.36}{}}
\newlabel{position_from_arc}{{37}{8}{Choosing the Dynamics Representation}{equation.3.37}{}}
\newlabel{error_prapagation}{{38}{8}{Choosing the Dynamics Representation}{equation.3.38}{}}
\newlabel{combined_error_relation}{{39}{8}{Choosing the Dynamics Representation}{equation.3.39}{}}
\newlabel{noises_for_v_w_phi}{{40}{9}{Choosing the Dynamics Representation}{equation.3.40}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-D}}Clustering the Dynamics with Dirichlet Processes}{9}{subsection.3.4}\protected@file@percent }
\newlabel{MLE}{{41}{9}{Clustering the Dynamics with Dirichlet Processes}{equation.3.41}{}}
\newlabel{nll}{{42}{9}{Clustering the Dynamics with Dirichlet Processes}{equation.3.42}{}}
\newlabel{modified_covariance_matrix}{{43}{9}{Clustering the Dynamics with Dirichlet Processes}{equation.3.43}{}}
\newlabel{MC_prior_integral}{{44}{9}{Clustering the Dynamics with Dirichlet Processes}{equation.3.44}{}}
\newlabel{MC_posterior}{{45}{9}{Clustering the Dynamics with Dirichlet Processes}{equation.3.45}{}}
\newlabel{posterior_convergence_estimate}{{46}{9}{Clustering the Dynamics with Dirichlet Processes}{equation.3.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Example of the convergence of parameter posterior in DPMM. Data are sampled from a infinite mixture of Gaussians, where the variance is fixed at 4, and the mean is given by a Gaussian mixture as the prior. As the cluster grows larger, the posterior of the mean becomes more narrowed and centred at the ground truth (5.5). }}{10}{figure.3}\protected@file@percent }
\newlabel{posterior_convergence}{{3}{10}{Example of the convergence of parameter posterior in DPMM. Data are sampled from a infinite mixture of Gaussians, where the variance is fixed at 4, and the mean is given by a Gaussian mixture as the prior. As the cluster grows larger, the posterior of the mean becomes more narrowed and centred at the ground truth (5.5)}{figure.3}{}}
\newlabel{refitted_weights}{{47}{10}{Clustering the Dynamics with Dirichlet Processes}{equation.3.47}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {III-E}}Learning the Dynamics Online}{10}{subsection.3.5}\protected@file@percent }
\newlabel{trained_mixture_model}{{48}{10}{Learning the Dynamics Online}{equation.3.48}{}}
\newlabel{MGP_posterior}{{49}{10}{Learning the Dynamics Online}{equation.3.49}{}}
\newlabel{MGP_indicator}{{50}{10}{Learning the Dynamics Online}{equation.3.50}{}}
\newlabel{posterior_convergence_simplification}{{51}{10}{Learning the Dynamics Online}{equation.3.51}{}}
\citation{PyBullet}
\citation{cully2015robots}
\newlabel{simplified_distortion}{{52}{11}{Learning the Dynamics Online}{equation.3.52}{}}
\newlabel{simplified_indicator}{{53}{11}{Learning the Dynamics Online}{equation.3.53}{}}
\@writefile{toc}{\contentsline {section}{\numberline {IV}Experiment}{11}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-A}}Robot Setup}{11}{subsection.4.1}\protected@file@percent }
\newlabel{PID}{{54}{11}{Robot Setup}{equation.4.54}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The Ant robot in PyBullet simulation. The four motors mounted on the body can rotate from $-40^{\circ }$ to $40^{\circ }$. The knee flexion angle for each leg ranges from $30^{\circ }$ to $100^{\circ }$. }}{11}{figure.4}\protected@file@percent }
\newlabel{Ant_robot}{{4}{11}{The Ant robot in PyBullet simulation. The four motors mounted on the body can rotate from $-40^{\circ }$ to $40^{\circ }$. The knee flexion angle for each leg ranges from $30^{\circ }$ to $100^{\circ }$}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The periodic motor targets corresponding to $\alpha = 0.8$, $\phi =100$ ms and $\tau =0.6$. The squared wave is smoothed by a Gaussian kernel with $\sigma = 100$ ms. }}{11}{figure.5}\protected@file@percent }
\newlabel{targets}{{5}{11}{The periodic motor targets corresponding to $\alpha = 0.8$, $\phi =100$ ms and $\tau =0.6$. The squared wave is smoothed by a Gaussian kernel with $\sigma = 100$ ms}{figure.5}{}}
\citation{QDgym}
\bibstyle{unsrt}
\bibdata{reference}
\bibcite{alphaGo}{1}
\bibcite{alphaStar}{2}
\bibcite{openAI5}{3}
\bibcite{MBRL}{4}
\bibcite{black_box_search}{5}
\bibcite{policy_search}{6}
\bibcite{curse_of_dim}{7}
\bibcite{QD}{8}
\bibcite{EvoRBC}{9}
\bibcite{RTE}{10}
\bibcite{GP}{11}
\bibcite{knn}{12}
\bibcite{k-means}{13}
\bibcite{Map-Elites}{14}
\bibcite{Q-Dax}{15}
\bibcite{evorbc_conf}{16}
\bibcite{GP_posterior}{17}
\bibcite{Matern}{18}
\bibcite{MCTS}{19}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The robot walking with one leg (left blue-yellow leg) damaged. The knee flexion angle of this leg is fixed at $30^{\circ }$ to reduce contact with the ground. }}{12}{figure.6}\protected@file@percent }
\newlabel{damaged_robot}{{6}{12}{The robot walking with one leg (left blue-yellow leg) damaged. The knee flexion angle of this leg is fixed at $30^{\circ }$ to reduce contact with the ground}{figure.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-B}}Generating the Repertoire with MAP-Elites}{12}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-C}}Determine the Basis with SVD}{12}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {IV-D}}Collecting Data Collaboratively}{12}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {V}Results and Analysis}{12}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-A}}Dirichlet Process Clustering}{12}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-B}}Dynamics Learning}{12}{subsection.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {\mbox  {V-C}}Tunnel Navigation Challenge}{12}{subsection.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {VI}Conclusion}{12}{section.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{References}{12}{section*.1}\protected@file@percent }
\bibcite{APROL}{20}
\bibcite{DP}{21}
\bibcite{Gibbs_sampling}{22}
\bibcite{Gibbs}{23}
\bibcite{variational_method}{24}
\bibcite{MCMC}{25}
\bibcite{Bayesian_mixture}{26}
\bibcite{EM}{27}
\bibcite{infinite_GMM}{28}
\bibcite{infinite_MGP}{29}
\bibcite{variational_MGP}{30}
\bibcite{PCA}{31}
\bibcite{Kasa_method}{32}
\bibcite{circle_fitting}{33}
\bibcite{L-BFGS-B}{34}
\bibcite{error_analysis}{35}
\bibcite{PyBullet}{36}
\bibcite{cully2015robots}{37}
\bibcite{QDgym}{38}
